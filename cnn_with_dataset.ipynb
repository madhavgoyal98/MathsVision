{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn with dataset.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madhavgoyal98/MathsVision/blob/models/cnn_with_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "6rYArwcIT2XM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "afb13242-118b-4b74-9dcd-f28bd7517ad0"
      },
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Xm4QOFixUEQP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f3d742d2-4499-47ea-e23b-1e7c5e8b1e3f"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GyTh3sASUaxs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "zf = ZipFile('/gdrive/My Drive/processed data.zip', 'r')\n",
        "zf.extractall('/gdrive/My Drive/processed data')\n",
        "zf.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5CAoki4rXJsf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "53cc43ee-f0a9-403f-b2f3-b5e342447588"
      },
      "cell_type": "code",
      "source": [
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(45, 45, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(75, activation='softmax'))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uLoj_w3PZ2Ms",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KAUF3-NAZ8Fz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ulnfv2lPbENg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sl3g8SmgbG7Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GiAQMm2PbKeR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c9468048-792c-455c-870b-7cc904147e56"
      },
      "cell_type": "code",
      "source": [
        "training_set = train_datagen.flow_from_directory('/content/processed data/training_set',\n",
        "                                                 target_size = (45, 45),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 109192 images belonging to 75 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UTLI7M_pbytI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a8526ff1-2a29-416f-b910-95a99221ff01"
      },
      "cell_type": "code",
      "source": [
        "test_set = test_datagen.flow_from_directory('/content/processed data/test_set',\n",
        "                                            target_size = (45, 45),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5513 images belonging to 75 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3g3zG7B4cGYp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3743
        },
        "outputId": "f150f5f7-b957-491d-ffdf-712841900dd6"
      },
      "cell_type": "code",
      "source": [
        "model.fit_generator(training_set,\n",
        "                         steps_per_epoch = 62,\n",
        "                         epochs = 100,\n",
        "                         validation_data = test_set,\n",
        "                         validation_steps = 100)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/100\n",
            "62/62 [==============================] - 21s 332ms/step - loss: 4.1988 - acc: 0.0267 - val_loss: 3.9787 - val_acc: 0.0791\n",
            "Epoch 2/100\n",
            "62/62 [==============================] - 16s 253ms/step - loss: 3.6139 - acc: 0.1492 - val_loss: 3.2264 - val_acc: 0.2191\n",
            "Epoch 3/100\n",
            "62/62 [==============================] - 16s 251ms/step - loss: 3.0108 - acc: 0.2460 - val_loss: 2.7005 - val_acc: 0.3300\n",
            "Epoch 4/100\n",
            "62/62 [==============================] - 16s 253ms/step - loss: 2.6197 - acc: 0.3211 - val_loss: 2.3737 - val_acc: 0.3843\n",
            "Epoch 5/100\n",
            "62/62 [==============================] - 16s 253ms/step - loss: 2.3381 - acc: 0.3740 - val_loss: 2.1396 - val_acc: 0.4378\n",
            "Epoch 6/100\n",
            "62/62 [==============================] - 16s 255ms/step - loss: 2.1667 - acc: 0.4113 - val_loss: 1.9896 - val_acc: 0.4756\n",
            "Epoch 7/100\n",
            "62/62 [==============================] - 16s 255ms/step - loss: 2.1249 - acc: 0.4148 - val_loss: 1.8954 - val_acc: 0.4998\n",
            "Epoch 8/100\n",
            "62/62 [==============================] - 16s 253ms/step - loss: 1.9052 - acc: 0.4753 - val_loss: 1.6399 - val_acc: 0.5450\n",
            "Epoch 9/100\n",
            "62/62 [==============================] - 16s 254ms/step - loss: 1.7966 - acc: 0.4975 - val_loss: 1.6749 - val_acc: 0.5364\n",
            "Epoch 10/100\n",
            "62/62 [==============================] - 16s 255ms/step - loss: 1.7143 - acc: 0.5257 - val_loss: 1.6125 - val_acc: 0.5519\n",
            "Epoch 11/100\n",
            "62/62 [==============================] - 16s 253ms/step - loss: 1.6646 - acc: 0.5217 - val_loss: 1.5086 - val_acc: 0.5719\n",
            "Epoch 12/100\n",
            "62/62 [==============================] - 16s 252ms/step - loss: 1.6405 - acc: 0.5312 - val_loss: 1.3354 - val_acc: 0.6166\n",
            "Epoch 13/100\n",
            "62/62 [==============================] - 16s 252ms/step - loss: 1.5261 - acc: 0.5680 - val_loss: 1.2597 - val_acc: 0.6402\n",
            "Epoch 14/100\n",
            "62/62 [==============================] - 16s 253ms/step - loss: 1.6016 - acc: 0.5519 - val_loss: 1.2465 - val_acc: 0.6220\n",
            "Epoch 15/100\n",
            "62/62 [==============================] - 16s 253ms/step - loss: 1.4496 - acc: 0.5701 - val_loss: 1.2467 - val_acc: 0.6406\n",
            "Epoch 16/100\n",
            "62/62 [==============================] - 15s 249ms/step - loss: 1.4353 - acc: 0.5857 - val_loss: 1.3155 - val_acc: 0.6226\n",
            "Epoch 17/100\n",
            "62/62 [==============================] - 16s 251ms/step - loss: 1.4381 - acc: 0.5922 - val_loss: 1.0901 - val_acc: 0.6850\n",
            "Epoch 18/100\n",
            "62/62 [==============================] - 16s 253ms/step - loss: 1.3282 - acc: 0.6164 - val_loss: 1.2480 - val_acc: 0.6364\n",
            "Epoch 19/100\n",
            "62/62 [==============================] - 16s 251ms/step - loss: 1.3323 - acc: 0.6033 - val_loss: 1.1189 - val_acc: 0.6709\n",
            "Epoch 20/100\n",
            "62/62 [==============================] - 16s 252ms/step - loss: 1.3467 - acc: 0.6134 - val_loss: 1.1698 - val_acc: 0.6563\n",
            "Epoch 21/100\n",
            "62/62 [==============================] - 16s 253ms/step - loss: 1.2889 - acc: 0.6346 - val_loss: 1.1038 - val_acc: 0.6824\n",
            "Epoch 22/100\n",
            "62/62 [==============================] - 16s 254ms/step - loss: 1.2992 - acc: 0.6190 - val_loss: 1.1169 - val_acc: 0.6656\n",
            "Epoch 23/100\n",
            "62/62 [==============================] - 16s 251ms/step - loss: 1.2805 - acc: 0.6326 - val_loss: 1.0718 - val_acc: 0.6849\n",
            "Epoch 24/100\n",
            "62/62 [==============================] - 16s 253ms/step - loss: 1.2001 - acc: 0.6447 - val_loss: 0.9987 - val_acc: 0.7106\n",
            "Epoch 25/100\n",
            "62/62 [==============================] - 16s 255ms/step - loss: 1.2384 - acc: 0.6421 - val_loss: 1.0336 - val_acc: 0.6871\n",
            "Epoch 26/100\n",
            "62/62 [==============================] - 16s 254ms/step - loss: 1.2024 - acc: 0.6492 - val_loss: 1.0104 - val_acc: 0.7051\n",
            "Epoch 27/100\n",
            "62/62 [==============================] - 16s 255ms/step - loss: 1.2114 - acc: 0.6436 - val_loss: 0.9607 - val_acc: 0.7247\n",
            "Epoch 28/100\n",
            "62/62 [==============================] - 16s 253ms/step - loss: 1.1990 - acc: 0.6386 - val_loss: 0.9417 - val_acc: 0.7199\n",
            "Epoch 29/100\n",
            "62/62 [==============================] - 15s 248ms/step - loss: 1.1210 - acc: 0.6729 - val_loss: 0.9459 - val_acc: 0.7044\n",
            "Epoch 30/100\n",
            "62/62 [==============================] - 16s 252ms/step - loss: 1.1531 - acc: 0.6562 - val_loss: 0.9734 - val_acc: 0.6991\n",
            "Epoch 31/100\n",
            "62/62 [==============================] - 16s 253ms/step - loss: 1.1524 - acc: 0.6714 - val_loss: 0.9333 - val_acc: 0.7216\n",
            "Epoch 32/100\n",
            "62/62 [==============================] - 16s 250ms/step - loss: 1.0756 - acc: 0.6754 - val_loss: 0.9364 - val_acc: 0.7211\n",
            "Epoch 33/100\n",
            "62/62 [==============================] - 16s 255ms/step - loss: 1.1015 - acc: 0.6759 - val_loss: 0.9143 - val_acc: 0.7340\n",
            "Epoch 34/100\n",
            "62/62 [==============================] - 16s 257ms/step - loss: 1.1388 - acc: 0.6880 - val_loss: 0.8701 - val_acc: 0.7388\n",
            "Epoch 35/100\n",
            "62/62 [==============================] - 16s 255ms/step - loss: 1.1248 - acc: 0.6618 - val_loss: 0.8737 - val_acc: 0.7381\n",
            "Epoch 36/100\n",
            "62/62 [==============================] - 16s 254ms/step - loss: 1.1024 - acc: 0.6653 - val_loss: 0.8751 - val_acc: 0.7372\n",
            "Epoch 37/100\n",
            "62/62 [==============================] - 16s 255ms/step - loss: 1.1108 - acc: 0.6799 - val_loss: 0.9005 - val_acc: 0.7268\n",
            "Epoch 38/100\n",
            "62/62 [==============================] - 16s 256ms/step - loss: 1.0588 - acc: 0.6900 - val_loss: 0.8417 - val_acc: 0.7400\n",
            "Epoch 39/100\n",
            "62/62 [==============================] - 16s 254ms/step - loss: 1.0557 - acc: 0.6920 - val_loss: 0.8507 - val_acc: 0.7422\n",
            "Epoch 40/100\n",
            "62/62 [==============================] - 16s 254ms/step - loss: 1.0578 - acc: 0.6966 - val_loss: 0.8320 - val_acc: 0.7482\n",
            "Epoch 41/100\n",
            "62/62 [==============================] - 16s 261ms/step - loss: 1.0755 - acc: 0.6734 - val_loss: 0.8902 - val_acc: 0.7297\n",
            "Epoch 42/100\n",
            "62/62 [==============================] - 16s 253ms/step - loss: 1.0228 - acc: 0.6956 - val_loss: 0.8593 - val_acc: 0.7312\n",
            "Epoch 43/100\n",
            "62/62 [==============================] - 16s 254ms/step - loss: 1.0067 - acc: 0.7167 - val_loss: 0.8637 - val_acc: 0.7384\n",
            "Epoch 44/100\n",
            "62/62 [==============================] - 16s 254ms/step - loss: 1.1214 - acc: 0.6719 - val_loss: 0.8475 - val_acc: 0.7428\n",
            "Epoch 45/100\n",
            "62/62 [==============================] - 16s 255ms/step - loss: 1.0049 - acc: 0.6961 - val_loss: 0.8635 - val_acc: 0.7347\n",
            "Epoch 46/100\n",
            "62/62 [==============================] - 16s 255ms/step - loss: 1.0292 - acc: 0.6991 - val_loss: 0.8212 - val_acc: 0.7481\n",
            "Epoch 47/100\n",
            "62/62 [==============================] - 16s 253ms/step - loss: 1.0483 - acc: 0.6991 - val_loss: 0.8190 - val_acc: 0.7450\n",
            "Epoch 48/100\n",
            "62/62 [==============================] - 16s 258ms/step - loss: 1.0222 - acc: 0.6946 - val_loss: 0.8080 - val_acc: 0.7447\n",
            "Epoch 49/100\n",
            "62/62 [==============================] - 16s 256ms/step - loss: 0.9574 - acc: 0.7051 - val_loss: 0.8567 - val_acc: 0.7334\n",
            "Epoch 50/100\n",
            "62/62 [==============================] - 16s 256ms/step - loss: 0.9868 - acc: 0.7006 - val_loss: 0.8467 - val_acc: 0.7331\n",
            "Epoch 51/100\n",
            "62/62 [==============================] - 16s 256ms/step - loss: 0.9450 - acc: 0.7188 - val_loss: 0.8060 - val_acc: 0.7614\n",
            "Epoch 52/100\n",
            "62/62 [==============================] - 16s 254ms/step - loss: 1.0235 - acc: 0.6794 - val_loss: 0.7850 - val_acc: 0.7513\n",
            "Epoch 53/100\n",
            "62/62 [==============================] - 16s 256ms/step - loss: 0.9719 - acc: 0.7107 - val_loss: 0.7637 - val_acc: 0.7700\n",
            "Epoch 54/100\n",
            "62/62 [==============================] - 16s 254ms/step - loss: 0.9479 - acc: 0.7016 - val_loss: 0.7905 - val_acc: 0.7664\n",
            "Epoch 55/100\n",
            "62/62 [==============================] - 16s 257ms/step - loss: 0.9762 - acc: 0.6961 - val_loss: 0.8138 - val_acc: 0.7534\n",
            "Epoch 56/100\n",
            "62/62 [==============================] - 16s 254ms/step - loss: 0.9611 - acc: 0.7107 - val_loss: 0.7822 - val_acc: 0.7517\n",
            "Epoch 57/100\n",
            "62/62 [==============================] - 16s 257ms/step - loss: 0.9876 - acc: 0.7051 - val_loss: 0.8585 - val_acc: 0.7312\n",
            "Epoch 58/100\n",
            "62/62 [==============================] - 16s 257ms/step - loss: 0.9576 - acc: 0.7112 - val_loss: 0.7627 - val_acc: 0.7535\n",
            "Epoch 59/100\n",
            "62/62 [==============================] - 16s 257ms/step - loss: 0.9465 - acc: 0.7112 - val_loss: 0.8611 - val_acc: 0.7441\n",
            "Epoch 60/100\n",
            "62/62 [==============================] - 16s 254ms/step - loss: 0.8497 - acc: 0.7314 - val_loss: 0.7604 - val_acc: 0.7681\n",
            "Epoch 61/100\n",
            "62/62 [==============================] - 16s 255ms/step - loss: 0.9108 - acc: 0.7193 - val_loss: 0.7672 - val_acc: 0.7501\n",
            "Epoch 62/100\n",
            "62/62 [==============================] - 16s 256ms/step - loss: 0.9475 - acc: 0.7258 - val_loss: 0.8076 - val_acc: 0.7475\n",
            "Epoch 63/100\n",
            "62/62 [==============================] - 16s 253ms/step - loss: 0.9323 - acc: 0.7238 - val_loss: 0.6876 - val_acc: 0.7828\n",
            "Epoch 64/100\n",
            "62/62 [==============================] - 16s 251ms/step - loss: 0.8768 - acc: 0.7374 - val_loss: 0.7246 - val_acc: 0.7784\n",
            "Epoch 65/100\n",
            "62/62 [==============================] - 16s 253ms/step - loss: 0.9271 - acc: 0.7182 - val_loss: 0.7368 - val_acc: 0.7740\n",
            "Epoch 66/100\n",
            "62/62 [==============================] - 16s 254ms/step - loss: 0.8746 - acc: 0.7319 - val_loss: 0.7888 - val_acc: 0.7576\n",
            "Epoch 67/100\n",
            "62/62 [==============================] - 16s 251ms/step - loss: 0.8776 - acc: 0.7379 - val_loss: 0.7400 - val_acc: 0.7716\n",
            "Epoch 68/100\n",
            "62/62 [==============================] - 16s 251ms/step - loss: 0.8511 - acc: 0.7354 - val_loss: 0.7135 - val_acc: 0.7759\n",
            "Epoch 69/100\n",
            "62/62 [==============================] - 16s 251ms/step - loss: 0.8892 - acc: 0.7334 - val_loss: 0.7637 - val_acc: 0.7694\n",
            "Epoch 70/100\n",
            "62/62 [==============================] - 16s 250ms/step - loss: 0.8739 - acc: 0.7550 - val_loss: 0.7201 - val_acc: 0.7699\n",
            "Epoch 71/100\n",
            "62/62 [==============================] - 16s 250ms/step - loss: 0.8983 - acc: 0.7283 - val_loss: 0.7555 - val_acc: 0.7762\n",
            "Epoch 72/100\n",
            "62/62 [==============================] - 15s 250ms/step - loss: 0.8746 - acc: 0.7233 - val_loss: 0.7755 - val_acc: 0.7712\n",
            "Epoch 73/100\n",
            "62/62 [==============================] - 16s 252ms/step - loss: 0.8633 - acc: 0.7389 - val_loss: 0.7478 - val_acc: 0.7727\n",
            "Epoch 74/100\n",
            "62/62 [==============================] - 15s 249ms/step - loss: 0.8900 - acc: 0.7238 - val_loss: 0.7292 - val_acc: 0.7775\n",
            "Epoch 75/100\n",
            "62/62 [==============================] - 15s 248ms/step - loss: 0.8885 - acc: 0.7404 - val_loss: 0.6766 - val_acc: 0.7954\n",
            "Epoch 76/100\n",
            "62/62 [==============================] - 15s 248ms/step - loss: 0.8454 - acc: 0.7394 - val_loss: 0.7505 - val_acc: 0.7594\n",
            "Epoch 77/100\n",
            "62/62 [==============================] - 15s 248ms/step - loss: 0.8403 - acc: 0.7540 - val_loss: 0.6670 - val_acc: 0.7916\n",
            "Epoch 78/100\n",
            "62/62 [==============================] - 15s 250ms/step - loss: 0.7951 - acc: 0.7445 - val_loss: 0.6816 - val_acc: 0.7809\n",
            "Epoch 79/100\n",
            "62/62 [==============================] - 15s 246ms/step - loss: 0.8486 - acc: 0.7530 - val_loss: 0.7120 - val_acc: 0.7881\n",
            "Epoch 80/100\n",
            "62/62 [==============================] - 16s 250ms/step - loss: 0.8995 - acc: 0.7293 - val_loss: 0.7429 - val_acc: 0.7636\n",
            "Epoch 81/100\n",
            "62/62 [==============================] - 15s 249ms/step - loss: 0.8616 - acc: 0.7228 - val_loss: 0.8135 - val_acc: 0.7469\n",
            "Epoch 82/100\n",
            "62/62 [==============================] - 15s 249ms/step - loss: 0.7965 - acc: 0.7566 - val_loss: 0.7198 - val_acc: 0.7932\n",
            "Epoch 83/100\n",
            "62/62 [==============================] - 16s 253ms/step - loss: 0.8394 - acc: 0.7475 - val_loss: 0.6535 - val_acc: 0.7916\n",
            "Epoch 84/100\n",
            "62/62 [==============================] - 15s 250ms/step - loss: 0.8543 - acc: 0.7445 - val_loss: 0.7520 - val_acc: 0.7680\n",
            "Epoch 85/100\n",
            "62/62 [==============================] - 15s 247ms/step - loss: 0.8175 - acc: 0.7566 - val_loss: 0.6951 - val_acc: 0.7784\n",
            "Epoch 86/100\n",
            "62/62 [==============================] - 16s 250ms/step - loss: 0.7845 - acc: 0.7525 - val_loss: 0.6865 - val_acc: 0.7784\n",
            "Epoch 87/100\n",
            "62/62 [==============================] - 16s 251ms/step - loss: 0.8275 - acc: 0.7510 - val_loss: 0.6875 - val_acc: 0.7765\n",
            "Epoch 88/100\n",
            "62/62 [==============================] - 16s 251ms/step - loss: 0.8528 - acc: 0.7409 - val_loss: 0.7444 - val_acc: 0.7738\n",
            "Epoch 89/100\n",
            "62/62 [==============================] - 16s 251ms/step - loss: 0.8820 - acc: 0.7319 - val_loss: 0.6805 - val_acc: 0.7822\n",
            "Epoch 90/100\n",
            "62/62 [==============================] - 15s 249ms/step - loss: 0.7789 - acc: 0.7596 - val_loss: 0.6289 - val_acc: 0.8111\n",
            "Epoch 91/100\n",
            "62/62 [==============================] - 15s 248ms/step - loss: 0.8250 - acc: 0.7515 - val_loss: 0.6338 - val_acc: 0.8019\n",
            "Epoch 92/100\n",
            "62/62 [==============================] - 15s 246ms/step - loss: 0.7913 - acc: 0.7681 - val_loss: 0.6388 - val_acc: 0.7963\n",
            "Epoch 93/100\n",
            "62/62 [==============================] - 16s 251ms/step - loss: 0.8230 - acc: 0.7520 - val_loss: 0.6207 - val_acc: 0.8128\n",
            "Epoch 94/100\n",
            "62/62 [==============================] - 15s 250ms/step - loss: 0.7778 - acc: 0.7646 - val_loss: 0.7128 - val_acc: 0.7923\n",
            "Epoch 95/100\n",
            "62/62 [==============================] - 15s 248ms/step - loss: 0.8161 - acc: 0.7566 - val_loss: 0.6724 - val_acc: 0.7909\n",
            "Epoch 96/100\n",
            "62/62 [==============================] - 16s 252ms/step - loss: 0.7817 - acc: 0.7742 - val_loss: 0.6050 - val_acc: 0.8083\n",
            "Epoch 97/100\n",
            "62/62 [==============================] - 15s 247ms/step - loss: 0.8056 - acc: 0.7555 - val_loss: 0.6790 - val_acc: 0.7879\n",
            "Epoch 98/100\n",
            "62/62 [==============================] - 16s 251ms/step - loss: 0.7961 - acc: 0.7636 - val_loss: 0.6427 - val_acc: 0.7972\n",
            "Epoch 99/100\n",
            "62/62 [==============================] - 15s 247ms/step - loss: 0.7630 - acc: 0.7681 - val_loss: 0.6873 - val_acc: 0.7834\n",
            "Epoch 100/100\n",
            "62/62 [==============================] - 15s 249ms/step - loss: 0.7581 - acc: 0.7676 - val_loss: 0.7005 - val_acc: 0.7756\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe365a79048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "LPFR60SclAJ9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save(\"/gdrive/My Drive/models/\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}